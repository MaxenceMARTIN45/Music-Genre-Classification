{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNzzL5dRVCAaJ1+UDq837zM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"6m8CsY-0JJpB","executionInfo":{"status":"ok","timestamp":1700131274769,"user_tz":-60,"elapsed":28103,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c6643915-a68b-4415-dc98-4898fe4ec315"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Importing working libraries\n","import os\n","import sys\n","import cv2\n","import json\n","import shutil\n","import random\n","import librosa\n","import requests\n","import datetime\n","import math as m\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from io import BytesIO\n","import librosa.display\n","import tensorflow as tf\n","from pathlib import Path\n","from keras import optimizers\n","from tensorflow import keras\n","from google.colab import drive # Comment when working in Visual Studio Code\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from tensorflow.keras import layers\n","from matplotlib import pyplot as plt\n","from tensorflow.keras.models import Model\n","from google.colab.patches import cv2_imshow # Comment when working in Visual Studio Code\n","from tensorflow.keras.models import load_model\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Import from my google drive\n","drive.mount('/content/drive') # Comment when working in Visual Studio Code\n","\n","# Loaded the main project folder\n","project_path = \"/content/drive/MyDrive/Colab Notebooks/Personal Project/Music Genre Classification\"\n","\n","# Image folder manager\n","images_original = os.path.join(project_path,\"data\",\"images_original\")\n","images_dataset = os.path.join(project_path,\"data\",\"images_dataset\")\n","images_dataset_train = os.path.join(images_dataset,\"train\")\n","images_dataset_validation = os.path.join(images_dataset,\"validation\")\n","images_dataset_test = os.path.join(images_dataset,\"test\")"]},{"cell_type":"code","source":["# # Generating Spectrograms from Audio\n","\n","# # Load the audio file\n","# audio_file = os.path.join(project_path,\"data\",\"genres_original\",\"blues\",\"blues.00000.wav\")\n","\n","# # Generate a spectrogram from the audio\n","# y, sr = librosa.load(audio_file)\n","\n","# # Generate a spectrogram from the audio\n","# D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n","\n","# # Display the spectrogram as an image\n","# plt.figure(figsize=(10, 6))\n","# librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n","# plt.colorbar(format='%+2.0f dB')\n","# plt.title('Audio Spectrogram')\n","# plt.show()"],"metadata":{"id":"pdfsXA2GIU_Q","executionInfo":{"status":"ok","timestamp":1700131274769,"user_tz":-60,"elapsed":4,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# # Splitting images_original to create images_dataset\n","\n","# # Create dataset, train, validation, and test folders\n","# os.makedirs(os.path.join(images_dataset, \"train\"), exist_ok=True)\n","# os.makedirs(os.path.join(images_dataset, \"validation\"), exist_ok=True)\n","# os.makedirs(os.path.join(images_dataset, \"test\"), exist_ok=True)\n","\n","# # Proportions\n","# proportion_train = 0.8\n","# proportion_validation = 0.1\n","# proportion_test = 0.1\n","\n","# # Iterate through each class folder\n","# for classe in os.listdir(images_original):\n","#     classe_path = os.path.join(images_original, classe)\n","#     if os.path.isdir(classe_path):\n","#         images = os.listdir(classe_path)\n","#         random.shuffle(images)\n","\n","#         # Divide the images into training, validation, and test sets\n","#         num_images = len(images)\n","#         num_train = int(num_images * proportion_train)\n","#         num_validation = int(num_images * proportion_validation)\n","\n","#         train_images = images[:num_train]\n","#         validation_images = images[num_train:num_train + num_validation]\n","#         test_images = images[num_train + num_validation:]\n","\n","#         # Copy the images to the respective folders\n","#         for image in train_images:\n","#             src = os.path.join(classe_path, image)\n","#             dest = os.path.join(images_dataset, \"train\", classe, image)\n","#             os.makedirs(os.path.dirname(dest), exist_ok=True)\n","#             shutil.copy(src, dest)\n","\n","#         for image in validation_images:\n","#             src = os.path.join(classe_path, image)\n","#             dest = os.path.join(images_dataset, \"validation\", classe, image)\n","#             os.makedirs(os.path.dirname(dest), exist_ok=True)\n","#             shutil.copy(src, dest)\n","\n","#         for image in test_images:\n","#             src = os.path.join(classe_path, image)\n","#             dest = os.path.join(images_dataset, \"test\", classe, image)\n","#             os.makedirs(os.path.dirname(dest), exist_ok=True)\n","#             shutil.copy(src, dest)"],"metadata":{"id":"ztC3m7YRQRBj","executionInfo":{"status":"ok","timestamp":1700131274769,"user_tz":-60,"elapsed":3,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Data preparation\n","\n","batch_size = 1 # Hyperparamètres d'exécution du modèle\n","# Plus le lot est petit, moins l'estimation du gradient est précise. En résumé : batchsize = le nombre d'exemples vus par le réseau en une seule backpropagation.\n","# img_height = 288\n","# img_width = 432\n","img_height,img_width,img_depth = 288,432,3\n","\n","# taille suivante associé au choix plus tard de x=16 -> nombre de neurones de la première couche\n","# n = sqrt(547 770/3x) = 106 -> n² = 11 236\n","# taille initiale : img_height,img_width,img_depth = 288,432,3\n","# proportion : prop_h = 288/(288+432) = 288/720 = 0.4 / prop_h = 432/(288+432) = 432/720 = 0.6\n","# nouvel taille : img_height = n * 2*prop_h = 106*2*0.4 = 84 / img_width = 127 -> 84*127 = 10 668 environ égale à 106² = 11 236\n","#img_height,img_width,img_depth = 84,127,3\n","\n","train_data = tf.keras.preprocessing.image_dataset_from_directory(\n","  images_dataset_train,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)\n","\n","# train_data = tf.keras.preprocessing.image_dataset_from_directory(images_dataset_train)\n","\n","# val_data = tf.keras.preprocessing.image_dataset_from_directory(\n","#   images_dataset_validation,\n","#   image_size=(img_height, img_width),\n","#   batch_size=batch_size)\n","\n","test_data = tf.keras.preprocessing.image_dataset_from_directory(\n","  images_dataset_test,\n","  image_size=(img_height, img_width),\n","  batch_size=batch_size)\n","\n","# test_data = tf.keras.preprocessing.image_dataset_from_directory(images_dataset_test)\n","\n","# class_names = train_data.class_names\n","# print(class_names)\n","# print(len(train_data.class_names))\n","# #print(len(val_data.class_names))\n","# print(len(test_data.class_names))\n","\n","#print(train_data)\n","\n","# print(train_data.shape)\n","\n","X_train_data = [np.array(X) for X,_ in train_data]\n","y_train_data = [int(y) for _,y in train_data]\n","\n","# print(X_train_data.shape)\n","# print(y_train_data.shape)\n","\n","X_test_data = [np.array(X) for X,_ in test_data]\n","y_test_data = [int(y) for _,y in test_data]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"enNC0tQnP4Zd","executionInfo":{"status":"ok","timestamp":1700131301526,"user_tz":-60,"elapsed":26759,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}},"outputId":"5e79c627-e75d-46c5-884f-4f2c63ffd5d8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 799 files belonging to 10 classes.\n","Found 101 files belonging to 10 classes.\n"]}]},{"cell_type":"code","source":["# # print(train_data.shape)\n","# print(len(train_data))\n","\n","# print(X_train_data.shape)\n","# print(y_train_data.shape)"],"metadata":{"id":"JRkKaYr3kJbV","executionInfo":{"status":"ok","timestamp":1700131301526,"user_tz":-60,"elapsed":15,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# # Data augmentation\n","\n","# # Définissez vos paramètres d'augmentation de données\n","# data_augmentation = tf.keras.Sequential([\n","#     tf.keras.layers.experimental.preprocessing.RandomFlip(\"vertical\"),\n","#     #tf.keras.layers.experimental.preprocessing.RandomZoom(0.2)\n","# ])\n","\n","# # Application de l'augmentation des données (seulement sur le training set)\n","# print(train_data)\n","# train_data = train_data.map(lambda x, y: (data_augmentation(x, training=True), y))\n","# print(train_data)"],"metadata":{"id":"X8gyiQ4ulnlK","executionInfo":{"status":"ok","timestamp":1700131301527,"user_tz":-60,"elapsed":14,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# # Display of a training set extract\n","\n","# plt.figure(figsize=(10, 10))\n","# for images, labels in train_data.take(1):\n","#   for i in range(batch_size):\n","#     print(images[i].shape)\n","#     # ax = plt.subplot(1,batch_size,i+1)\n","#     # plt.imshow(images[i].numpy().astype(\"uint8\"))\n","#     # plt.title(class_names[labels[i]])\n","#     # plt.axis(\"off\")"],"metadata":{"id":"0bn7Wq9EQFjo","executionInfo":{"status":"ok","timestamp":1700131301527,"user_tz":-60,"elapsed":13,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# import os\n","# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# # Définir le chemin du dossier contenant les données d'entraînement\n","# #data_dir = 'chemin/vers/images_dataset_train'\n","\n","# # Définir la taille des images et le lot (batch size)\n","# #img_height,img_width,img_depth = 288,432,3\n","# img_size = (288,432)\n","# batch_size = 1\n","\n","# # Utiliser un générateur d'images pour charger les données\n","# datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","# # Charger les données d'entraînement\n","# train_generator = datagen.flow_from_directory(\n","#     images_dataset_train,\n","#     target_size=img_size,\n","#     batch_size=batch_size,\n","#     class_mode='categorical',  # 'categorical' pour les étiquettes one-hot encoded\n","#     subset='training'  # Spécifier le sous-ensemble comme ensemble d'entraînement\n","# )\n","\n","# # Charger les données de validation\n","# validation_generator = datagen.flow_from_directory(\n","#     images_dataset_validation,\n","#     target_size=img_size,\n","#     batch_size=batch_size,\n","#     class_mode='categorical',\n","#     subset='validation'  # Spécifier le sous-ensemble comme ensemble de validation\n","# )\n","\n","# print(train_generator)\n","\n","# # Extraire les données d'entraînement et d'étiquettes d'entraînement\n","# X_train_data, y_train_data = next(train_generator)\n","\n","# # Afficher la forme des données d'entraînement\n","# print(\"Shape of X_train_data:\", X_train_data.shape)\n","# print(\"Shape of y_train_data:\", y_train_data.shape)\n","\n","# print(len(X_train_data))\n","# print(len(y_train_data))\n","# print(y_train_data)\n","\n","# # Extraire les données d'entraînement et d'étiquettes d'entraînement\n","# X_train_data, y_train_data = next(train_generator)\n","\n","# # Afficher la forme des données d'entraînement\n","# print(\"Shape of X_train_data:\", X_train_data.shape)\n","# print(\"Shape of y_train_data:\", y_train_data.shape)\n","\n","# print(len(X_train_data))\n","# print(len(y_train_data))\n","# print(y_train_data)"],"metadata":{"id":"rnfz9RqfdlMK","executionInfo":{"status":"ok","timestamp":1700131302030,"user_tz":-60,"elapsed":514,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# # Fonction pour extraire les images et les étiquettes\n","# def extract_images_labels(images, labels):\n","#     return images, labels\n","\n","# # Utiliser la méthode map pour appliquer la fonction d'extraction aux éléments de l'ensemble de données\n","# train_data = train_data.map(extract_images_labels)\n","\n","# # Diviser les données en X_train_data et y_train_data\n","# X_train_data, y_train_data = zip(*train_data)\n","\n","# # Convertir les listes en tableaux numpy (si nécessaire)\n","# X_train_data = tf.concat(X_train_data, axis=0)\n","# y_train_data = tf.concat(y_train_data, axis=0)\n","\n","# # Vérifier les dimensions\n","# print(\"Dimensions de X_train_data :\", X_train_data.shape)\n","# print(\"Dimensions de y_train_data :\", y_train_data.shape)\n","\n","# print(len(train_data))\n","\n","# # Extraire les données d'entraînement\n","# for X_train_data, y_train_data in train_data:\n","#     #print(X_train_data, y_train_data)\n","#     print(len(X_train_data))\n","#     print(len(y_train_data))\n","#     #print(X_train_data)\n","#     print(y_train_data)\n","#     # Vous pouvez accéder à X_train_data et y_train_data directement ici\n","#     break\n","\n","# X_train_data = []\n","# y_train_data = []\n","\n","# for X,y in train_data:\n","#     X_train_data.append(X)\n","#     y_train_data.append(y.astype(int))\n","\n","# import numpy as np\n","\n","# X_train_data = [np.array(X) for X,_ in train_data]\n","# y_train_data = [int(y) for _,y in train_data]\n","\n","\n","# X_train_data, y_train_data = zip(*train_data)\n","\n","# X_train_data, y_train_data = map(np.array, zip(*train_data))\n","# X_train_data = X_train_data.astype(int)\n","# y_train_data = y_train_data.astype(int)\n","\n","\n","# print(len(X_train_data))\n","# print(len(y_train_data))\n","# #print(X_train_data)\n","# print(y_train_data)\n","\n","# X_train_data, y_train_data = train_data\n","\n","# print(len(train_data.class_names))\n","# #print(len(val_data.class_names))\n","# print(len(test_data.class_names))\n","\n","\n","\n","\n","\n","# X_train_data = [np.array(X) for X,_ in train_data]\n","# y_train_data = [int(y) for _,y in train_data]\n","\n","# X_test_data = [np.array(X) for X,_ in test_data]\n","# y_test_data = [int(y) for _,y in test_data]\n","\n","# --------------------------------------------------------------------------------\n","\n","# Convertir les listes en tableaux NumPy\n","X_train_data_array = np.array(X_train_data)\n","y_train_data_array = np.array(y_train_data)\n","\n","# Remodeler les données si nécessaire (remplacez 5 par le nombre réel de dimensions)\n","X_train_data_reshaped = X_train_data_array.reshape((X_train_data_array.shape[0], -1))\n","y_train_data_reshaped = y_train_data_array.reshape((y_train_data_array.shape[0], -1))\n","\n","# --------------------------------------------------------------------------------\n","\n","# Convertir les listes en tableaux NumPy\n","X_test_data_array = np.array(X_test_data)\n","y_test_data_array = np.array(y_test_data)\n","\n","# Remodeler les données si nécessaire (remplacez 5 par le nombre réel de dimensions)\n","X_test_data_reshaped = X_test_data_array.reshape((X_test_data_array.shape[0], -1))\n","y_test_data_reshaped = y_test_data_array.reshape((y_test_data_array.shape[0], -1))\n","\n","\n","\n"],"metadata":{"id":"TJ-5taIXZw8o","executionInfo":{"status":"ok","timestamp":1700131302700,"user_tz":-60,"elapsed":675,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["print(X_train_data_reshaped.shape)\n","print(y_train_data_reshaped.shape)\n","\n","print(X_test_data_reshaped.shape)\n","print(y_test_data_reshaped.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"trE_47I-n_3q","executionInfo":{"status":"ok","timestamp":1700131302700,"user_tz":-60,"elapsed":4,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}},"outputId":"4ce69938-acd5-4fdc-ac63-b52ae22fc44e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["(799, 373248)\n","(799, 1)\n","(101, 373248)\n","(101, 1)\n"]}]},{"cell_type":"code","source":["# Supposons que vous ayez déjà effectué l'ACP comme décrit dans votre code\n","from sklearn.decomposition import PCA\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","X_train = X_train_data_reshaped#.T\n","\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","# X_test_scaled = scaler.transform(X_test)\n","\n","print(X_train.shape)\n","\n","# Créer l'objet PCA\n","n = 798\n","pca = PCA(n_components=n)\n","\n","# Transformer les données d'apprentissage\n","X_train_pca = pca.fit_transform(X_train_scaled)\n","\n","print(X_train_pca.shape)\n","\n","# # Transformer les données de test\n","# X_test_pca = pca.transform(X_test_scaled)\n","\n","# Calculer la variance expliquée par chaque composante principale\n","explained_variance_ratio = pca.explained_variance_ratio_\n","\n","# Imprimer la variance expliquée par chaque composante principale\n","print(\"Variance expliquée par chaque composante principale:\", explained_variance_ratio)\n","\n","# Imprimer la variance totale expliquée par les deux composantes principales\n","total_variance_explained = sum(explained_variance_ratio)\n","print(\"Variance totale expliquée par les deux composantes principales:\", total_variance_explained)\n","# meilleur var = 42 avec 50 composantes pour l'instant\n"],"metadata":{"id":"ICMhT4XirAgs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700131821000,"user_tz":-60,"elapsed":176497,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}},"outputId":"88369dec-07ac-440d-caf2-14f2dd04f1e8"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["(799, 373248)\n","(799, 798)\n","Variance expliquée par chaque composante principale: [1.93465889e-01 3.76675315e-02 2.26670634e-02 1.20526319e-02\n"," 9.53316409e-03 8.16321932e-03 7.71656306e-03 5.63821476e-03\n"," 5.18934382e-03 5.07750874e-03 4.57497081e-03 4.49765753e-03\n"," 4.09648474e-03 3.96681437e-03 3.71471141e-03 3.59467114e-03\n"," 3.50152212e-03 3.39588523e-03 3.27456975e-03 3.19811585e-03\n"," 3.13695753e-03 3.09890858e-03 3.00254067e-03 2.95068976e-03\n"," 2.91627157e-03 2.84494809e-03 2.83617061e-03 2.78864312e-03\n"," 2.76036048e-03 2.74372008e-03 2.72644893e-03 2.65224581e-03\n"," 2.58625438e-03 2.55734031e-03 2.54886877e-03 2.52381503e-03\n"," 2.51999032e-03 2.46877968e-03 2.45506503e-03 2.44269613e-03\n"," 2.43205903e-03 2.37821601e-03 2.36541033e-03 2.33054953e-03\n"," 2.32078275e-03 2.29592249e-03 2.28278735e-03 2.26103468e-03\n"," 2.24315911e-03 2.22498341e-03 2.21239589e-03 2.18935264e-03\n"," 2.15992844e-03 2.13633548e-03 2.12129857e-03 2.09108833e-03\n"," 2.07551150e-03 2.07080413e-03 2.04211776e-03 2.03893753e-03\n"," 2.01939489e-03 2.01072567e-03 1.99350831e-03 1.98930455e-03\n"," 1.97311048e-03 1.95897953e-03 1.95001869e-03 1.94189267e-03\n"," 1.92878523e-03 1.92348985e-03 1.91794953e-03 1.90861803e-03\n"," 1.88670901e-03 1.87179074e-03 1.85505941e-03 1.84520101e-03\n"," 1.83490675e-03 1.82589144e-03 1.81407982e-03 1.79863186e-03\n"," 1.79315323e-03 1.78634364e-03 1.77561829e-03 1.76093774e-03\n"," 1.74950087e-03 1.74133759e-03 1.72344013e-03 1.71826256e-03\n"," 1.71124947e-03 1.69693376e-03 1.69059052e-03 1.68069976e-03\n"," 1.67713035e-03 1.67347142e-03 1.65377057e-03 1.64595083e-03\n"," 1.63879956e-03 1.63381954e-03 1.61990372e-03 1.61631103e-03\n"," 1.61344570e-03 1.60193630e-03 1.59529841e-03 1.58690882e-03\n"," 1.58501288e-03 1.57726998e-03 1.57456985e-03 1.56463298e-03\n"," 1.55736844e-03 1.55126280e-03 1.54612027e-03 1.54039927e-03\n"," 1.53483311e-03 1.52463210e-03 1.51801680e-03 1.51430990e-03\n"," 1.50571985e-03 1.50184357e-03 1.49581616e-03 1.48932880e-03\n"," 1.48334377e-03 1.47416000e-03 1.46851235e-03 1.46727217e-03\n"," 1.45905872e-03 1.45642099e-03 1.44292507e-03 1.44254742e-03\n"," 1.43628637e-03 1.42709911e-03 1.42554881e-03 1.41288538e-03\n"," 1.41152332e-03 1.40581175e-03 1.40320917e-03 1.39507954e-03\n"," 1.39022514e-03 1.38485420e-03 1.38004962e-03 1.37465447e-03\n"," 1.36832881e-03 1.36455125e-03 1.36045855e-03 1.35649950e-03\n"," 1.35145849e-03 1.34877663e-03 1.34136516e-03 1.33851427e-03\n"," 1.32900965e-03 1.32760825e-03 1.32170063e-03 1.31777429e-03\n"," 1.31684483e-03 1.31133990e-03 1.30656746e-03 1.30434381e-03\n"," 1.30072318e-03 1.29470869e-03 1.28861878e-03 1.28715776e-03\n"," 1.28021301e-03 1.27686199e-03 1.27222214e-03 1.26505340e-03\n"," 1.26118772e-03 1.26057840e-03 1.25721027e-03 1.25472201e-03\n"," 1.25019869e-03 1.24667876e-03 1.24244986e-03 1.23810233e-03\n"," 1.23178645e-03 1.22846977e-03 1.22387032e-03 1.22134364e-03\n"," 1.21593697e-03 1.20832946e-03 1.20749080e-03 1.20401511e-03\n"," 1.20010949e-03 1.19626895e-03 1.19218219e-03 1.18920684e-03\n"," 1.18736294e-03 1.18617434e-03 1.18136511e-03 1.17810117e-03\n"," 1.17582711e-03 1.17375457e-03 1.16567372e-03 1.16169185e-03\n"," 1.16104586e-03 1.15903316e-03 1.15112890e-03 1.14893576e-03\n"," 1.14760792e-03 1.14588009e-03 1.14357844e-03 1.13573775e-03\n"," 1.13387406e-03 1.13241654e-03 1.13007834e-03 1.12596736e-03\n"," 1.12272392e-03 1.11947302e-03 1.11771387e-03 1.10893056e-03\n"," 1.10855675e-03 1.10403320e-03 1.10053725e-03 1.09886436e-03\n"," 1.09773292e-03 1.09271018e-03 1.08967093e-03 1.08429731e-03\n"," 1.08187494e-03 1.07540481e-03 1.07372878e-03 1.07101956e-03\n"," 1.07054890e-03 1.06898858e-03 1.06786226e-03 1.06338051e-03\n"," 1.06014160e-03 1.05805497e-03 1.05281384e-03 1.05135317e-03\n"," 1.04875630e-03 1.04572880e-03 1.04394113e-03 1.04152528e-03\n"," 1.03824586e-03 1.03698205e-03 1.03507855e-03 1.02923391e-03\n"," 1.02889899e-03 1.02498813e-03 1.02078647e-03 1.02017412e-03\n"," 1.01569272e-03 1.01504300e-03 1.01310969e-03 1.01285451e-03\n"," 1.00840558e-03 1.00450311e-03 1.00257352e-03 1.00071612e-03\n"," 9.99010168e-04 9.95348440e-04 9.94263333e-04 9.91816865e-04\n"," 9.91256791e-04 9.87374806e-04 9.81525751e-04 9.80545301e-04\n"," 9.77457850e-04 9.76640848e-04 9.71953501e-04 9.69780318e-04\n"," 9.68492939e-04 9.63510654e-04 9.62774211e-04 9.60852311e-04\n"," 9.56073054e-04 9.55574098e-04 9.53903422e-04 9.50879650e-04\n"," 9.50268062e-04 9.47965658e-04 9.46276472e-04 9.45199921e-04\n"," 9.41281673e-04 9.39942722e-04 9.36856610e-04 9.31201095e-04\n"," 9.29904811e-04 9.28378024e-04 9.25008906e-04 9.22431529e-04\n"," 9.22049279e-04 9.21123195e-04 9.18273407e-04 9.17008088e-04\n"," 9.14618664e-04 9.12359217e-04 9.09846043e-04 9.08659305e-04\n"," 9.05952358e-04 9.04629065e-04 9.02058673e-04 9.01004823e-04\n"," 8.98158993e-04 8.96065030e-04 8.94535857e-04 8.91114352e-04\n"," 8.89283081e-04 8.86824680e-04 8.85370187e-04 8.83987115e-04\n"," 8.81488726e-04 8.79753032e-04 8.77713959e-04 8.77057260e-04\n"," 8.74943857e-04 8.72989709e-04 8.70237011e-04 8.68338975e-04\n"," 8.66115850e-04 8.62578687e-04 8.61441018e-04 8.58311076e-04\n"," 8.57041567e-04 8.52935773e-04 8.51166202e-04 8.50322191e-04\n"," 8.46569310e-04 8.45327973e-04 8.42345122e-04 8.41794012e-04\n"," 8.39176006e-04 8.37998057e-04 8.37416970e-04 8.33319267e-04\n"," 8.32887832e-04 8.30180594e-04 8.29016557e-04 8.26931500e-04\n"," 8.25488998e-04 8.24167393e-04 8.23124778e-04 8.21599970e-04\n"," 8.20597692e-04 8.18012981e-04 8.17642722e-04 8.15234846e-04\n"," 8.12246581e-04 8.10524740e-04 8.09561810e-04 8.06925993e-04\n"," 8.04038486e-04 8.03116360e-04 8.00461450e-04 7.98816385e-04\n"," 7.98154913e-04 7.94068386e-04 7.93556334e-04 7.92258070e-04\n"," 7.90264807e-04 7.89635989e-04 7.87812518e-04 7.86790100e-04\n"," 7.85811048e-04 7.81163399e-04 7.80382659e-04 7.77932059e-04\n"," 7.76204572e-04 7.73442269e-04 7.71506806e-04 7.69736420e-04\n"," 7.68729660e-04 7.67029705e-04 7.66748912e-04 7.63782358e-04\n"," 7.62966694e-04 7.61584146e-04 7.59921502e-04 7.59101647e-04\n"," 7.57032016e-04 7.55552319e-04 7.54329027e-04 7.52098975e-04\n"," 7.49944418e-04 7.48349470e-04 7.47621991e-04 7.46601028e-04\n"," 7.44566612e-04 7.42820208e-04 7.40630261e-04 7.39056908e-04\n"," 7.36193266e-04 7.33296154e-04 7.32562155e-04 7.31807959e-04\n"," 7.30267784e-04 7.28387735e-04 7.26503669e-04 7.25202786e-04\n"," 7.24125712e-04 7.22360157e-04 7.20136042e-04 7.19052798e-04\n"," 7.16282579e-04 7.14315218e-04 7.12493202e-04 7.11147441e-04\n"," 7.08550971e-04 7.07947183e-04 7.04905193e-04 7.03526835e-04\n"," 7.03187718e-04 7.01183337e-04 7.00053468e-04 6.98623597e-04\n"," 6.97038602e-04 6.94909308e-04 6.93607959e-04 6.91938563e-04\n"," 6.90783665e-04 6.89082022e-04 6.88298314e-04 6.85345964e-04\n"," 6.84613711e-04 6.83683844e-04 6.80409488e-04 6.79426244e-04\n"," 6.77661039e-04 6.76652824e-04 6.75338786e-04 6.72952272e-04\n"," 6.71205693e-04 6.69344619e-04 6.68700959e-04 6.66802749e-04\n"," 6.65851752e-04 6.63958490e-04 6.63272571e-04 6.62456267e-04\n"," 6.60713646e-04 6.59325800e-04 6.58506993e-04 6.56022632e-04\n"," 6.54591480e-04 6.53507130e-04 6.51562063e-04 6.50630856e-04\n"," 6.48474088e-04 6.48078276e-04 6.45160209e-04 6.43847859e-04\n"," 6.42066123e-04 6.41507038e-04 6.40899176e-04 6.40256505e-04\n"," 6.38237630e-04 6.36418466e-04 6.35983539e-04 6.34279975e-04\n"," 6.32427284e-04 6.30231516e-04 6.29354327e-04 6.27148431e-04\n"," 6.26711699e-04 6.25798479e-04 6.24524371e-04 6.22617081e-04\n"," 6.21721323e-04 6.19872124e-04 6.18584920e-04 6.17326703e-04\n"," 6.16340491e-04 6.15255616e-04 6.13846583e-04 6.12060889e-04\n"," 6.11241092e-04 6.10457209e-04 6.08368195e-04 6.07124064e-04\n"," 6.05027424e-04 6.04398898e-04 6.02337415e-04 6.00534317e-04\n"," 5.99969469e-04 5.98445302e-04 5.97164501e-04 5.95506048e-04\n"," 5.94277575e-04 5.93921868e-04 5.92181575e-04 5.89693547e-04\n"," 5.88569848e-04 5.86022041e-04 5.85480477e-04 5.83979709e-04\n"," 5.81553206e-04 5.80806925e-04 5.80349704e-04 5.79454179e-04\n"," 5.78215462e-04 5.76799968e-04 5.75359387e-04 5.73929748e-04\n"," 5.73142548e-04 5.72173856e-04 5.71014010e-04 5.69718715e-04\n"," 5.67077252e-04 5.66229341e-04 5.64674672e-04 5.63303300e-04\n"," 5.62341185e-04 5.61186927e-04 5.60858927e-04 5.60347049e-04\n"," 5.58684580e-04 5.57827763e-04 5.54870232e-04 5.53780177e-04\n"," 5.52461075e-04 5.50883764e-04 5.48611220e-04 5.47935022e-04\n"," 5.46899741e-04 5.45999559e-04 5.45455958e-04 5.42769325e-04\n"," 5.41583926e-04 5.41106332e-04 5.39636298e-04 5.37784654e-04\n"," 5.36823994e-04 5.36484586e-04 5.34429972e-04 5.33583749e-04\n"," 5.32497768e-04 5.31268539e-04 5.29539306e-04 5.28485223e-04\n"," 5.26559714e-04 5.25008654e-04 5.24820411e-04 5.24149276e-04\n"," 5.22030343e-04 5.21637558e-04 5.20475383e-04 5.18731074e-04\n"," 5.16522792e-04 5.15056308e-04 5.14409912e-04 5.13239880e-04\n"," 5.12384169e-04 5.10352256e-04 5.09130128e-04 5.07844263e-04\n"," 5.06049022e-04 5.04527532e-04 5.03430434e-04 5.02499170e-04\n"," 5.01299975e-04 5.00599446e-04 4.99121379e-04 4.98341687e-04\n"," 4.97364206e-04 4.96496214e-04 4.96115303e-04 4.93914064e-04\n"," 4.93664935e-04 4.92478779e-04 4.91024577e-04 4.89628932e-04\n"," 4.87340818e-04 4.85525554e-04 4.84855904e-04 4.84041026e-04\n"," 4.83425392e-04 4.81715979e-04 4.80177754e-04 4.79169859e-04\n"," 4.77400870e-04 4.76077897e-04 4.74890636e-04 4.74059780e-04\n"," 4.73649066e-04 4.71971318e-04 4.71063831e-04 4.69877647e-04\n"," 4.69107938e-04 4.68613347e-04 4.66549653e-04 4.64758341e-04\n"," 4.64286190e-04 4.62012656e-04 4.61772375e-04 4.60739044e-04\n"," 4.58703696e-04 4.57701302e-04 4.57458897e-04 4.55753645e-04\n"," 4.55057627e-04 4.54108376e-04 4.53320827e-04 4.51531057e-04\n"," 4.50068881e-04 4.48827486e-04 4.47917264e-04 4.46597347e-04\n"," 4.46400227e-04 4.43750061e-04 4.42264165e-04 4.41579497e-04\n"," 4.39326541e-04 4.38328425e-04 4.37596143e-04 4.36099537e-04\n"," 4.35086957e-04 4.34394169e-04 4.33561567e-04 4.32376255e-04\n"," 4.31418302e-04 4.29240637e-04 4.28420317e-04 4.27229301e-04\n"," 4.26474551e-04 4.23974561e-04 4.23089310e-04 4.22433193e-04\n"," 4.21216158e-04 4.20249329e-04 4.18365671e-04 4.17303643e-04\n"," 4.16318275e-04 4.15258750e-04 4.13112110e-04 4.12323308e-04\n"," 4.10471926e-04 4.10317065e-04 4.08632826e-04 4.07281477e-04\n"," 4.05767583e-04 4.05643135e-04 4.04111866e-04 3.99977784e-04\n"," 3.99340206e-04 3.98251286e-04 3.97953845e-04 3.96899588e-04\n"," 3.95676034e-04 3.93932045e-04 3.93574941e-04 3.92826070e-04\n"," 3.90302739e-04 3.89834342e-04 3.88988003e-04 3.88357759e-04\n"," 3.85675288e-04 3.85427586e-04 3.84601823e-04 3.83525621e-04\n"," 3.81829654e-04 3.81329475e-04 3.79199890e-04 3.76162498e-04\n"," 3.75501520e-04 3.73679301e-04 3.72788083e-04 3.71865288e-04\n"," 3.70185531e-04 3.69960791e-04 3.68872250e-04 3.65283340e-04\n"," 3.64284206e-04 3.63521976e-04 3.61809041e-04 3.61083192e-04\n"," 3.60145641e-04 3.58852732e-04 3.57757468e-04 3.55565542e-04\n"," 3.54476389e-04 3.52777162e-04 3.52321047e-04 3.51780473e-04\n"," 3.49301699e-04 3.48163187e-04 3.47694819e-04 3.44806263e-04\n"," 3.43834778e-04 3.43659311e-04 3.41906212e-04 3.40166560e-04\n"," 3.39118415e-04 3.37919948e-04 3.35770485e-04 3.35360121e-04\n"," 3.33890843e-04 3.30602139e-04 3.30542098e-04 3.29137780e-04\n"," 3.26724286e-04 3.26500711e-04 3.25159897e-04 3.23911227e-04\n"," 3.22478096e-04 3.20403022e-04 3.17832688e-04 3.15233716e-04\n"," 3.14674573e-04 3.13103985e-04 3.12308286e-04 3.11881071e-04\n"," 3.09085473e-04 3.08949529e-04 3.06931179e-04 3.04071436e-04\n"," 3.03199893e-04 3.02023429e-04 3.00921354e-04 2.99918669e-04\n"," 2.98964704e-04 2.97805120e-04 2.97463092e-04 2.96111335e-04\n"," 2.93611432e-04 2.92619545e-04 2.92176788e-04 2.90445925e-04\n"," 2.88345036e-04 2.87142699e-04 2.84821406e-04 2.84482026e-04\n"," 2.82710564e-04 2.81647604e-04 2.80738750e-04 2.79577012e-04\n"," 2.76856561e-04 2.76123057e-04 2.74877122e-04 2.73871759e-04\n"," 2.72453501e-04 2.70357414e-04 2.68732401e-04 2.67591939e-04\n"," 2.65633309e-04 2.63157941e-04 2.62653804e-04 2.60925939e-04\n"," 2.59505963e-04 2.58699205e-04 2.54176150e-04 2.52910511e-04\n"," 2.50737095e-04 2.50195037e-04 2.46480718e-04 2.43882023e-04\n"," 2.42293565e-04 2.40898822e-04 2.39294983e-04 2.37508531e-04\n"," 2.33991930e-04 2.33123195e-04 2.32185208e-04 2.29600933e-04\n"," 2.26948090e-04 2.25644122e-04 2.23493233e-04 2.21688359e-04\n"," 2.18953617e-04 2.17962777e-04 2.16983914e-04 2.16136148e-04\n"," 2.13512190e-04 2.10405720e-04 2.06353376e-04 2.03136573e-04\n"," 1.99631380e-04 1.96591121e-04 1.92093066e-04 1.90483144e-04\n"," 1.85882178e-04 1.84250472e-04 1.81586787e-04 1.80479299e-04\n"," 1.76597037e-04 1.75666355e-04 1.71387946e-04 1.65871577e-04\n"," 1.63422839e-04 1.61293108e-04 1.57590752e-04 1.41179233e-04\n"," 1.15316274e-04 8.66630944e-05 1.50869084e-06 5.43590311e-08\n"," 1.62659344e-08 1.41006256e-08 1.40441809e-08 1.25435946e-08\n"," 9.42982847e-09 2.96164537e-09 1.13698198e-14 1.10674392e-14\n"," 8.06737726e-15 7.21246013e-16 3.60952820e-16 1.68530427e-16\n"," 1.19727538e-16 8.41715698e-17]\n","Variance totale expliquée par les deux composantes principales: 0.9999999495758589\n"]}]},{"cell_type":"code","source":["# Initialiser le modèle k-NN avec le nombre de voisins (k) souhaité\n","k = 2\n","knn_model = KNeighborsClassifier(n_neighbors=k)\n","\n","# Entraîner le modèle sur les données d'entraînement\n","knn_model.fit(X_train_pca,y_train_data_reshaped)\n","\n","# Faire des prédictions sur les données de test\n","y_pred = knn_model.predict(X_train_pca)\n","\n","y_train_data_reshaped = y_train_data_reshaped.flatten()\n","# print(y_train_data_reshaped)\n","# print(y_pred)\n","\n","# Calculer la précision du modèle\n","accuracy = accuracy_score(y_train_data_reshaped,y_pred)\n","print(f\"Précision du modèle : {accuracy}\")\n","\n","# ----------\n","\n","# # Faire des prédictions sur les données de test\n","# y_pred = knn_model.predict(X_train_data_reshaped)\n","\n","# y_train_data_reshaped = y_train_data_reshaped.flatten()\n","# print(y_train_data_reshaped)\n","# print(y_pred)\n","\n","# # Calculer la précision du modèle\n","# accuracy = accuracy_score(y_train_data_reshaped,y_pred)\n","# print(f\"Précision du modèle : {accuracy}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_FVfj92Xnvb1","executionInfo":{"status":"ok","timestamp":1700134065402,"user_tz":-60,"elapsed":470,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}},"outputId":"280f39ac-775e-44f8-c4a9-175ed1ca81c6"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Précision du modèle : 0.49687108886107634\n"]}]},{"cell_type":"code","source":["# Model creation\n","\n","num_classes = 10\n","\n","# model = tf.keras.Sequential([ # Hyperparamètres des couches (layers)\n","#     layers.experimental.preprocessing.Rescaling(1./255),\n","#     layers.Conv2D(128,4, activation='relu'), # Kernel Size # Méthode d'activation des couches cachées\n","#     layers.MaxPooling2D(),\n","#     layers.Conv2D(64,4, activation='relu'),\n","#     layers.MaxPooling2D(),\n","#     layers.Conv2D(32,4, activation='relu'),\n","#     layers.MaxPooling2D(),\n","#     layers.Conv2D(16,4, activation='relu'),\n","#     layers.MaxPooling2D(),\n","#     layers.Flatten(),\n","#     layers.Dropout(0.5), # Dropout # Regularization of my model which overfits too much\n","#     layers.Dense(64,activation='relu'),\n","#     layers.Dense(num_classes, activation='softmax') # Méthode d'activation du layer final\n","# ])\n","\n","# img_height,img_width,img_depth = 288,432,3\n","\n","# model = tf.keras.Sequential([ # Hyperparamètres des couches (layers)\n","#     #layers.experimental.preprocessing.Rescaling(1./255),\n","#     layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height,img_width,img_depth)),\n","#     layers.Conv2D(128,4, activation='relu'), # Kernel Size # Méthode d'activation des couches cachées\n","#     layers.MaxPooling2D(),\n","#     layers.Conv2D(64,4, activation='relu'),\n","#     layers.MaxPooling2D(),\n","#     layers.Conv2D(32,4, activation='relu'),\n","#     layers.MaxPooling2D(),\n","#     layers.Conv2D(16,4, activation='relu'),\n","#     layers.MaxPooling2D(),\n","#     layers.Flatten(),\n","#     layers.Dropout(0.5), # Dropout # Regularization of my model which overfits too much\n","#     layers.Dense(64,activation='relu'),\n","#     layers.Dense(num_classes, activation='softmax') # Méthode d'activation du layer final\n","# ])\n","\n","\n","\n","#img_height,img_width,img_depth = 288,432,3\n","\n","model = tf.keras.Sequential([\n","    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, img_depth)),\n","    layers.Flatten(input_shape=(img_height, img_width, img_depth)),\n","    layers.Dense(1000, activation='relu'),\n","    #layers.Dropout(0.25), # Rajouter si résultat moyen mais en bonne voie\n","    layers.Dense(500, activation='relu'),\n","    layers.Dense(250, activation='relu'),\n","    layers.Dense(125, activation='relu'),\n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(32, activation='relu'),\n","    layers.Dense(16, activation='relu'),\n","    layers.Dense(num_classes, activation='softmax') # num_classes = 10\n","])\n","\n","model.compile(optimizer='adam',  # You can choose other optimizers like 'sgd', 'rmsprop', etc.\n","              loss='sparse_categorical_crossentropy',  # Use 'categorical_crossentropy' if your labels are one-hot encoded\n","              metrics=['accuracy'])\n","\n","# model.compile( # Hyperparamètres de compilation du modèle\n","#     optimizer='adam', # Optimizer -> descente de gradient stochastique (SGD), Adam, RMSprop, etc.\n","#     loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False), # Loss utilisée\n","#     metrics=['accuracy'])\n","\n","\n","# model.compile(\n","#     optimizer=optimizers.RMSprop(lr=1e-4),\n","#     loss='binary_crossentropy',\n","#     metrics=['acc'])\n","\n","# Build the model by specifying an input shape\n","# input_shape = (img_width,img_height,3)  # Adjust this based on your input data shape\n","# model.build(input_shape)\n","\n","# Afficher le résumé du modèle, y compris le nombre de paramètres\n","model.summary()"],"metadata":{"id":"rytV_fAFTwpz","executionInfo":{"status":"aborted","timestamp":1700131363776,"user_tz":-60,"elapsed":5,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model training\n","total_epochs = 30 # Hyperparamètres d'exécution du modèle\n","#X minutes per epoch -> X hours X minutes for Y training epochs\n","step_epochs = 2\n","\n","print(\"--> Training start time : \", datetime.datetime.now().strftime('%H:%M:%S'))\n","\n","# Create a loop to train the model in steps\n","for i in range(0, total_epochs+1, step_epochs):\n","    start_epoch = i\n","    end_epoch = min(i + step_epochs, total_epochs)\n","\n","    print(f\"--> Training epochs {start_epoch + 1} to {end_epoch}\")\n","\n","    model.fit(\n","        train_data,\n","        validation_data=val_data,\n","        initial_epoch=start_epoch,\n","        epochs=end_epoch\n","    )\n","\n","    # Save the model after each step\n","    #template_file = os.path.join(project_path, \"models\", f\"model_{end_epoch}_epochs\")\n","    #model.save(template_file)\n","\n","print(\"--> Training end time : \", datetime.datetime.now().strftime('%H:%M:%S'))"],"metadata":{"id":"FSYm0yFXGfKc","executionInfo":{"status":"aborted","timestamp":1700131363776,"user_tz":-60,"elapsed":5,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Restart model training at epoch number X\n","start_again_epoch_number = 30\n","\n","# Load model from file\n","template_file = os.path.join(project_path,\"models\",\"model_\" + str(start_again_epoch_number) + \"_epochs\")\n","model = load_model(template_file)\n","\n","# Model training\n","total_epochs = 60 # Hyperparamètres d'exécution du modèle\n","# X minutes per epoch -> X hours X minutes for Y training epochs\n","step_epochs = 2\n","\n","print(\"--> Training start time : \", datetime.datetime.now().strftime('%H:%M:%S'))\n","\n","# Create a loop to train the model in steps\n","for i in range(start_again_epoch_number, total_epochs+1, step_epochs):\n","    start_epoch = i\n","    end_epoch = min(i + step_epochs, total_epochs)\n","\n","    print(f\"--> Training epochs {start_epoch + 1} to {end_epoch}\")\n","\n","    model.fit(\n","        train_data,\n","        validation_data=val_data,\n","        initial_epoch=start_epoch,\n","        epochs=end_epoch\n","    )\n","\n","    # Save the model after each step\n","    #template_file = os.path.join(project_path, \"models\", f\"model_{end_epoch}_epochs\")\n","    #model.save(template_file)\n","\n","print(\"--> Training end time : \", datetime.datetime.now().strftime('%H:%M:%S'))"],"metadata":{"id":"x-iyFnspzFte","executionInfo":{"status":"aborted","timestamp":1700131363776,"user_tz":-60,"elapsed":4,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Load model from file\n","# template_file = os.path.join(project_path,\"models\",\"model_26_epochs\")\n","# model = load_model(template_file)"],"metadata":{"id":"HjjdaQ4eGkjy","executionInfo":{"status":"aborted","timestamp":1700131363776,"user_tz":-60,"elapsed":4,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Model evaluation\n","# evaluation_results = model.evaluate(test_data)\n","\n","# # Print evaluation results\n","# print(\"Validation loss:\", evaluation_results[0])\n","# print(\"Validation accuracy:\", evaluation_results[1])"],"metadata":{"id":"RKnNOQwvFeTk","executionInfo":{"status":"aborted","timestamp":1700131363776,"user_tz":-60,"elapsed":4,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Préparer l'affichage de la courbe d'apprentissage permettant de déterminer l'overfitting\n","\n","start = 1\n","end = 30\n","step = 1\n","\n","train_losses, val_losses, test_losses = [], [], []\n","train_accuracies, val_accuracies, test_accuracies = [], [], []\n","\n","for i in range(start, end+1, step):\n","    # Load model from file\n","    template_file = os.path.join(project_path, \"models\", \"model_\" + str(i) + \"_epochs\")\n","    model = tf.keras.models.load_model(template_file)\n","\n","    # Evaluation\n","    train_evaluation = model.evaluate(train_data)\n","    val_evaluation = model.evaluate(val_data)\n","    test_evaluation = model.evaluate(test_data)\n","\n","    # Store evaluation results\n","    train_losses.append(train_evaluation[0])\n","    val_losses.append(val_evaluation[0])\n","    test_losses.append(test_evaluation[0])\n","\n","    train_accuracies.append(train_evaluation[1])\n","    val_accuracies.append(val_evaluation[1])\n","    test_accuracies.append(test_evaluation[1])"],"metadata":{"id":"dxZVSywYJVdU","executionInfo":{"status":"aborted","timestamp":1700131363776,"user_tz":-60,"elapsed":4,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Afficher la courbe d'apprentissage permettant de déterminer l'overfitting\n","\n","# Create plots\n","epochs = list(range(start, end+1, step))\n","\n","plt.figure(figsize=(12, 5))\n","\n","# Plot loss\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs, train_losses, 'bo-', label='Train Loss')\n","plt.plot(epochs, val_losses, 'ro-', label='Validation Loss')\n","plt.plot(epochs, test_losses, 'go-', label='Test Loss')\n","plt.title('Loss vs. Number of Epochs')\n","plt.xlabel('Number of Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","# Plot accuracy\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs, train_accuracies, 'bo-', label='Train Accuracy')\n","plt.plot(epochs, val_accuracies, 'ro-', label='Validation Accuracy')\n","plt.plot(epochs, test_accuracies, 'go-', label='Test Accuracy')\n","plt.title('Accuracy vs. Number of Epochs')\n","plt.xlabel('Number of Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"metadata":{"id":"1vMOMJKtcHSy","executionInfo":{"status":"aborted","timestamp":1700131363776,"user_tz":-60,"elapsed":4,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Visual Evaluation of Results for Humans\n","\n","# plt.figure(figsize=(10, 10))\n","# for images, labels in test_data.take(1):\n","#   # Prediction\n","#   predictions = model.predict(images)\n","#   predicted_classes = predictions.argmax(axis=-1)\n","#   # Display\n","#   for i in range(batch_size):\n","#     plt.figure(figsize=(12, 6))\n","#     # Display the true class\n","#     plt.subplot(1, 2, 1)\n","#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n","#     plt.title(\"True class: \" + class_names[labels[i]])\n","#     plt.axis(\"off\")\n","#     # Display the prediction\n","#     plt.subplot(1, 2, 2)\n","#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n","#     plt.title(\"Prediction: \" + class_names[predicted_classes[i]])\n","#     plt.axis(\"off\")\n","#   plt.show()"],"metadata":{"id":"x6IWCt3I0Lk9","executionInfo":{"status":"aborted","timestamp":1700131363776,"user_tz":-60,"elapsed":4,"user":{"displayName":"Maxence MARTIN","userId":"05470086628208192496"}}},"execution_count":null,"outputs":[]}]}